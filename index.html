<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Senya is Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167092781-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-167092781-1');
  </script>


  <title>Senya Ashukha</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Arsenii (Senya) Ashukha</name>
              </p>
              <p>I am a PhD candidate at <a href="https://bayesgroup.ru"> Bayesian methods research group</a> and <a href="https://research.samsung.com/aicenter_moscow">Samsung AI Center Moscow</a> with <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Dmitriy Vetrov</a>, where I work on probabilistic deep learning. 
              </p>
              <p align=center>
                <a href="mailto:ars.ashuha@gmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://senya-ashukha.github.io/arsenii-ashukha-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IU-kuP8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/senya-ashukha">GitHub</a> &nbsp/&nbsp
                <a href="https://twitter.com/senya_ashuha">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/images/senya-ashukha.jpg"><img style="border-radius:50%;width:100%;max-width:100%" alt="profile photo" src="images/senya-ashukha.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in deep learning, probabilistic inference, uncertainty estimation, and learning with limited data. My works have been focused on understanding and applications of variational inference in deep neural networks. Representative papers are highlighted.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/pitfalls_unc_ens_iclr20/pic.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=BJxI5gHKDr">
                <papertitle>Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.ru/citations?user=5LXTi40AAAAJ&hl=en">Alexander Lyzhov*</a>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICLR</em>, 2020  
              <br>
              <a href="https://senya-ashukha.github.io/pitfalls-uncertainty&ensembling">blog post</a> / 
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">poster video (5mins)</a> / 
                <a href="https://github.com/bayesgroup/pytorch-ensembles">code</a> / 
                <a href="https://arxiv.org/abs/2002.06470">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/pitfalls_unc_ens_iclr20/paper.txt" target="_blank">bibtex</a>
              <p></p>
              <p>
            The work introduces <i>calibrated log-likelihood</i> a reliable uncertainty estimation metric, <i>deep ensemble equivalent</i> an interpretable technique for comparison of ensembles, and points out that <i>test-time augmentation</i>  is a simple technique that allows to improve ensembles for free.</p>  
            </td>
          </tr> 

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/svdo_icml17/svdo_prev.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="http://proceedings.mlr.press/v70/molchanov17a.html">
                <papertitle>Variational Dropout Sparsifies Deep Neural Networks</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICML</em>, 2017  
              <br>
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">icml talk (15 mins)</a> /  
                <a href="https://arxiv.org/abs/1701.05369">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/svdo_icml17/paper.txt" target="_blank">bibtex</a> / 
                <a href="https://github.com/bayesgroup/variational-dropout-sparsifies-dnn">code (Theano)</a> /
                <a href="https://github.com/google-research/google-research/tree/master/state_of_sparsity/layers/variational_dropout" target="_blank">TF code by Google AI</a> / 
                <a href="https://colab.research.google.com/github/bayesgroup/deepbayes-2019/blob/master/seminars/day6/SparseVD-solution.ipynb" target="_blank">Colab PyTorch</a>


                
              <p></p>
              <p>
              Variational dropout secretly trains highly sparsified deep neural networks, while a pattern of sparsity is learned jointly with weights during training.</p>
            </td>
          </tr> 
          </table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p align="right">
                <a href="https://people.eecs.berkeley.edu/~barron/">This guy makes nice webpages.</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
