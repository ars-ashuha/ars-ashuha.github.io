<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Senya is Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167092781-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-167092781-1');
  </script>


  <title>Senya Ashukha</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Arsenii (Senya) Ashukha</name>
              </p>
              <p>I am a PhD candidate at <a href="https://bayesgroup.ru"> Bayesian methods research group</a> and <a href="https://research.samsung.com/aicenter_moscow">Samsung AI Center Moscow</a> with <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Dmitriy Vetrov</a>, where I work on probabilistic deep learning. 
              </p>
              <p align=center>
                <a href="mailto:ars.ashuha@gmail.com" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://senya-ashukha.github.io/arsenii-ashukha-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IU-kuP8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/senya-ashukha">GitHub</a> &nbsp/&nbsp
                <a href="https://twitter.com/senya_ashuha">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/images/senya-ashukha.jpg"><img style="border-radius:50%;width:100%;max-width:100%" alt="profile photo" src="images/senya-ashukha.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
              <li style="margin:0 0 3px 0;"> 
                <a href="https://arxiv.org/abs/2002.09103"> Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation</a> has been accepted to UAI 2020!
              </li>
              <li> 
                <a href="https://openreview.net/forum?id=BJxI5gHKDr"> Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning</a> is accepted to ICLR 2020
                <!-- <br/>See 
                <a href="https://senya-ashukha.github.io/pitfalls-uncertainty&ensembling">blog post</a> / 
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">poster video (5mins)</a> / 
                <a href="https://github.com/bayesgroup/pytorch-ensembles">code</a> / 
                <a href="https://arxiv.org/abs/2002.06470">arXiv</a> / 
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:WTOnuMCFoL8J:scholar.google.com/&output=citation&scisdr=CgUBNv0ZEJ2E6zDYBk8:AAGBfm0AAAAAXsPdHk_U9RdHmxItQ8YmTwNIOH9c-Ex8&scisig=AAGBfm0AAAAAXsPdHqLj9y3WvWN7skx5TAeT4r_13Plz&scisf=4&ct=citation&cd=-1&hl=en" target="_blank">bibtex</a>. -->
              </li>
              <li style="margin:0 0 3px 0;"> 
                Two papers <a href="https://openreview.net/forum?id=ByGuynAct7"> The Deep  Weight Prior</a> (a joint work with AMLab UvA) and <a href="https://openreview.net/forum?id=B1GAUs0cKQ"> Variance Networks</a> are accepted to ICLR 2019
              </li>
              <li style="margin:0 0 3px 0;"> 
                I joined ML lab at <a href="https://research.samsung.com/aicenter_moscow">Samsung AI Center Moscow</a> as a student researcher. 
              </li>
              <li style="margin:0 0 3px 0;"> 
                <a href="http://proceedings.mlr.press/v70/molchanov17a.html"> StructuredBP via Log-Normal Multiplicative Noise </a> is accepted to NeurIPS 2017
              </li>
              <li style="margin:0 0 3px 0;"> 
                <a href="http://proceedings.mlr.press/v70/molchanov17a.html"> Variational Dropout Sparsifies DNNs</a> is accepted to ICML 2017
              </li>
            </ul>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in deep learning, probabilistic inference, and generative models.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/pitfalls_unc_ens_iclr20/pic.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=BJxI5gHKDr">
                <papertitle>Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning</papertitle>
              </a>
              <br>
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.ru/citations?user=5LXTi40AAAAJ&hl=en">Alexander Lyzhov*</a>,
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICLR</em>, 2020  
              <br>
              <a href="https://senya-ashukha.github.io/pitfalls-uncertainty&ensembling">blog post</a> / 
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">poster video (5mins)</a> / 
                <a href="https://github.com/bayesgroup/pytorch-ensembles">code</a> / 
                <a href="https://arxiv.org/abs/2002.06470">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/pitfalls_unc_ens_iclr20/paper.txt" target="_blank">bibtex</a>
              <p></p>
              <p>
              Many uncertainty estimation metrics (e.g., log-likelihood) are unreliable and should not be used for benchmarking. The "efficient" methods for training ensembles have the same performance as Deep Ensemble of only few networks, while simple test-time data augmentation improves all ensembles with no additional training or evaluation cost! </p>
            </td>
          </tr> 

          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffff">
            <td style="padding:15px;width:25%;vertical-align:middle">
                <img src='projects/svdo_icml17/svdo_prev.png' width="160px">
            </td>
            <td style="padding:15px;width:75%;vertical-align:middle">
              <a href="http://proceedings.mlr.press/v70/molchanov17a.html">
                <papertitle>Variational Dropout Sparsifies Deep Neural Networks</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=tJ6JXRYAAAAJ&hl=en">Dmitry Molchanov*</a>,
              <strong>Arsenii Ashukha*</strong>,
              <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
              <br>
                <em>ICML</em>, 2017  
              <br>
                <a href="https://iclr.cc/virtual_2020/poster_BJxI5gHKDr.html">icml talk (15 mins)</a> /  
                <a href="https://arxiv.org/abs/1701.05369">arXiv</a> / 
                <a href="https://senya-ashukha.github.io/projects/svdo_icml17/paper.txt" target="_blank">bibtex</a> / 
                <a href="https://github.com/bayesgroup/variational-dropout-sparsifies-dnn">code (Theano)</a> /
                <a href="https://github.com/google-research/google-research/tree/master/state_of_sparsity/layers/variational_dropout" target="_blank">TF code by Google AI</a> / 
                <a href="https://colab.research.google.com/github/bayesgroup/deepbayes-2019/blob/master/seminars/day6/SparseVD-solution.ipynb" target="_blank">Colab PyTorch</a>


                
              <p></p>
              <p>
              Variational dropout secretly trains highly sparsified deep neural networks, while a pattern of sparsity is learned jointly with weights during training.</p>
            </td>
          </tr> 
          </table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p align="right">
                <a href="https://people.eecs.berkeley.edu/~barron/">This guy makes nice webpages.</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
